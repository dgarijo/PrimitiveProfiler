{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn.svm.classes.SVC\n",
      "sklearn.preprocessing.label.LabelEncoder\n",
      "{\"primitive_catalog\": [{\"Name\": \"SVC\", \"id\": \"sklearn.svm.classes.SVC\", \"Task\": \"Modeling\", \"LearningType\": \"Classification\", \"Requirements\": [\"NUMERICAL\", \"NON-MISSING-VALUES\"], \"Performance\": [{\"rows\": \"100\", \"columns\": \"350\", \"time\": 0.015965938568115234}, {\"rows\": \"100\", \"columns\": \"50\", \"time\": 0.003998994827270508}, {\"rows\": \"300\", \"columns\": \"350\", \"time\": 0.12764334678649902}, {\"rows\": \"300\", \"columns\": \"50\", \"time\": 0.024962902069091797}, {\"rows\": \"600\", \"columns\": \"350\", \"time\": 0.522212028503418}, {\"rows\": \"600\", \"columns\": \"50\", \"time\": 0.08600711822509766}]}, {\"Name\": \"LabelEncoder\", \"id\": \"sklearn.preprocessing.label.LabelEncoder\", \"IsArray\": true, \"Requirements\": [\"NON-MISSING-VALUES\"], \"Performance\": [{\"rows\": \"100\", \"columns\": \"350\", \"time\": 0.04904294013977051}, {\"rows\": \"100\", \"columns\": \"50\", \"time\": 0.010004997253417969}, {\"rows\": \"300\", \"columns\": \"350\", \"time\": 0.07406878471374512}, {\"rows\": \"300\", \"columns\": \"50\", \"time\": 0.010021209716796875}, {\"rows\": \"600\", \"columns\": \"350\", \"time\": 0.0994415283203125}, {\"rows\": \"600\", \"columns\": \"50\", \"time\": 0.014005899429321289}]}]}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import importlib\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import time\n",
    "\n",
    "def class_for_name(module_name, class_name):\n",
    "    try:\n",
    "        # load the module, will raise ImportError if module cannot be loaded\n",
    "        m = importlib.import_module(module_name)\n",
    "        # get the class, will raise AttributeError if class cannot be found\n",
    "        c = getattr(m, class_name)()\n",
    "        return c\n",
    "    except:\n",
    "        print('Could not load module: '+module_name+'.'+class_name)\n",
    "        return -1\n",
    "\n",
    "#Data: dataset to test (from the test datasets that illustrate different requirements)\n",
    "#Primitive: primitive being tested. We assume it has the fit() method\n",
    "#The second field returned indicates whether the primitives needs an array or not\n",
    "def passTest(data, primitive):\n",
    "    target = data.iloc[:,-1]\n",
    "    train = data.drop(data.columns[[len(data.columns)-1]], axis=1) #drop target column (the last one)\n",
    "    #test\n",
    "    try:\n",
    "        y_pred = primitive.fit(train,target).predict(train)# Not all primitives have a predict, but should have fit\n",
    "        #print(\"PASSED: \"+data.name)\n",
    "        #print (y_pred)\n",
    "        return True, False\n",
    "    except Exception as e:\n",
    "        #print(e)\n",
    "        try:\n",
    "            y_pred = primitive.fit(train).transform(train)\n",
    "            #print (y_pred)\n",
    "            return True, False\n",
    "        except:\n",
    "            #Some primitives can only be applied to arrays, not matrix!\n",
    "            try:\n",
    "                for col in train.columns:\n",
    "                    #print (col)\n",
    "                    #Need to do the transform, otherwise exceptions may not be raised\n",
    "                    y_pred = primitive.fit(train[col]).transform(train[col])\n",
    "                return True, True\n",
    "            except: \n",
    "                return False, False\n",
    "        #print(\"NOT PASSED: \" +data.name)\n",
    "        \n",
    "\n",
    "\n",
    "#Path: String with the path to the dataset folders. The system assumes to have three: clean_data, requirement_data and performance_data\n",
    "#Primitive module name: string with the module name. E.g., 'sklearn.svm'\n",
    "#Primitive name: string with the name of the primitive to be loaded. E.g., 'SVC'\n",
    "#testPerformance: boolean that is true if you want to test the performance tests (will require more time)\n",
    "def getPrimitiveRequirements(path, primitiveModuleName, primitiveName, testPerformance):\n",
    "    CLEAN = path + \"clean_data\"\n",
    "    REQ = path + \"requirement_data\"\n",
    "    PERF = path + \"performance_data\"\n",
    "    primExec =  class_for_name(primitiveModuleName,primitiveName)\n",
    "    if(primExec == -1):\n",
    "        print(\"The primitive module could not be loaded.\")\n",
    "        return -1\n",
    "    prim = {}\n",
    "    #prim = Primitive(primitiveName)\n",
    "    prim[\"Name\"] = primitiveName\n",
    "    prim[\"id\"] = primitiveModuleName+\".\"+primitiveName\n",
    "    #Clean data files: all primitives should pass these tests\n",
    "    data_clean_int = pd.read_csv(CLEAN +'/int_clean_data.csv')\n",
    "    data_clean_float = pd.read_csv(CLEAN +'/float_clean_data.csv')\n",
    "    data_clean_int.name = \"CLEAN DATA INT\" \n",
    "    data_clean_float.name = \"CLEAN DATA FLOAT\"\n",
    "    \n",
    "    if not hasattr(primExec, 'fit'):\n",
    "        print(\"Primitive does not have fit method. No requirements considered\")\n",
    "        return -1\n",
    "    \n",
    "    passed, p = (passTest(data_clean_int, primExec)) and (passTest(data_clean_float, primExec))\n",
    "    #print(passed)\n",
    "    if(not passed):\n",
    "        print(\"The primitive \"+primitiveName+\" cannot execute the clean datasets. No further requirements addressed\")\n",
    "        return -1\n",
    "    \n",
    "    if hasattr(primExec, 'predict'):\n",
    "        #primitive is a classifier/regression\n",
    "        target = data_clean_float.iloc[:,-1]\n",
    "        train = data_clean_float.drop(data_clean_float.columns[[len(data_clean_float.columns)-1]], axis=1) #drop target column (the last one)\n",
    "        y_pred = primExec.fit(train,target).predict(train)\n",
    "        prim[\"Task\"] = \"Modeling\"        \n",
    "        if issubclass(y_pred.dtype.type, np.floating):\n",
    "            prim[\"LearningType\"] = \"Regression\"\n",
    "        else:\n",
    "            prim[\"LearningType\"] = \"Classification\"\n",
    "        \n",
    "    \n",
    "    #Rest of the tests\n",
    "    onlyfiles = [f for f in listdir(REQ) if isfile(join(REQ, f))]\n",
    "    requirements = []\n",
    "    for d in onlyfiles:\n",
    "        data = pd.read_csv(REQ+\"/\"+d)\n",
    "        data.name = d\n",
    "        passed,array = passTest(data, primExec)\n",
    "        if (\"missing\" in data.name) and (not passed) and (\"NON-MISSING-VALUES\" not in requirements):\n",
    "            #print(\"Primitive cannot handle missing values\")\n",
    "            requirements.append(\"NON-MISSING-VALUES\")\n",
    "        if (\"categorical\" in data.name) and (not passed) and (\"NUMERICAL\" not in requirements):\n",
    "            #print(\"Primitive cannot handle string/categorical values\")\n",
    "            requirements.append(\"NUMERICAL\")\n",
    "        if (\"unique\" in data.name) and (not passed) and (\"NOT-UNIQUE\" not in requirements):\n",
    "            #print(\"Primitive cannot handle having a column of unique values\")\n",
    "            requirements.append(\"NOT-UNIQUE\")\n",
    "        if (\"negative\" in data.name) and (not passed) and (\"NON-NEGATIVE\" not in requirements):\n",
    "            #print(\"Primitive cannot handle negative values\")\n",
    "            requirements.append(\"NON-NEGATIVE\")\n",
    "        if(array):\n",
    "            #prim.isArray = True\n",
    "            prim[\"IsArray\"] = True\n",
    "    prim[\"Requirements\"] = requirements\n",
    "            \n",
    "    if(testPerformance):\n",
    "        onlyfiles = [f for f in listdir(PERF) if isfile(join(PERF, f))]\n",
    "        performance = []\n",
    "        for d in onlyfiles:\n",
    "            data = pd.read_csv(PERF+\"/\"+d)\n",
    "            data.name = d\n",
    "            start = time.time()\n",
    "            passed,array = passTest(data, primExec)\n",
    "            end = time.time()\n",
    "            total = end - start\n",
    "            #print(data.name +\": \"+ str(end - start))  \n",
    "            fileNames = re.findall(r'\\d+', data.name)\n",
    "            element = {}\n",
    "            element[\"rows\"] = fileNames[0]\n",
    "            element[\"columns\"] = fileNames[1]\n",
    "            element[\"time\"] = total\n",
    "            performance.append(element)\n",
    "        prim[\"Performance\"] = performance\n",
    "    return prim\n",
    "      \n",
    "def allPrimitivesToText(jsonFile):\n",
    "    output = []\n",
    "    for i in data['search_primitives']:\n",
    "        if i[\"is_class\"]: #necessary because otherwise it will attempt to try many primitives that may even download data\n",
    "            primitive = i[\"id\"]\n",
    "            print (primitive [:primitive.rindex('.')]+\".\"+primitive [primitive.rindex('.')+1:])\n",
    "            p = getPrimitiveRequirements(DATADIR,primitive [:primitive.rindex('.')],primitive [primitive.rindex('.')+1:],True)\n",
    "            if(p != -1):\n",
    "                output.append(p)\n",
    "                #print (primitiveToJSON(p))\n",
    "    primitives = {}\n",
    "    primitives[\"primitive_catalog\"] = output\n",
    "    #TO DO: Return JSON dumps of the array\n",
    "    return json.dumps(primitives)\n",
    "        \n",
    "#Main script        \n",
    "DATADIR = \"data_profiler/\" #Dir with the profiling datasets\n",
    "import json\n",
    "#print(json.dumps(getPrimitiveRequirements(DATADIR,'sklearn.svm','SVC',True)))\n",
    "#print (primitiveToJSON(getPrimitiveRequirements(DATADIR,'sklearn.svm','SVC',True)))\n",
    "#print (json.dumps(getPrimitiveRequirements(DATADIR,'sklearn.linear_model','LinearRegression',True)))\n",
    "#print (json.dumps(getPrimitiveRequirements(DATADIR,'sklearn.preprocessing','LabelEncoder',True)))\n",
    "\n",
    "#print (json.dumps(getPrimitiveRequirements(DATADIR,'sklearn.feature_extraction.text','TfidfVectorizer',False)))\n",
    "#sklearn.metrics.scorer.get_scorer\n",
    "#print (json.dumps(getPrimitiveRequirements(DATADIR,'sklearn.linear_model.sgd_fast','Regression',False)))\n",
    "#print (json.dumps(getPrimitiveRequirements(DATADIR,'sklearn.decomposition.dict_learning','DictionaryLearning',False)))\n",
    "\n",
    "from pprint import pprint\n",
    "import json\n",
    "\n",
    "#JSON with the primitives by Khe-Thia\n",
    "with open('sklearn-supersimple.json') as data_file:    \n",
    "    data = json.load(data_file)\n",
    "print(allPrimitivesToText(data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
