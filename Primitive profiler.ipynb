{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float_100_350.csv: 0.015002012252807617\n",
      "float_100_50.csv: 0.004004240036010742\n",
      "float_300_350.csv: 0.1300971508026123\n",
      "float_300_50.csv: 0.026957988739013672\n",
      "float_600_350.csv: 0.5237033367156982\n",
      "float_600_50.csv: 0.09051036834716797\n",
      "{\n",
      "\"class\": \"sklearn.svm.SVC\",\n",
      "\"name\": \"SVC\",\n",
      "\"LearningType\": \"Classification\",\n",
      "\"requirements\":[\"NON-MISSING-VALUES\",\"NUMERICAL\"]\n",
      "}\n",
      "\n",
      "float_100_350.csv: 0.004458427429199219\n",
      "float_100_50.csv: 0.0019996166229248047\n",
      "float_300_350.csv: 0.01400136947631836\n",
      "float_300_50.csv: 0.0025000572204589844\n",
      "float_600_350.csv: 0.025495052337646484\n",
      "float_600_50.csv: 0.0025010108947753906\n",
      "{\n",
      "\"class\": \"sklearn.linear_model.LinearRegression\",\n",
      "\"name\": \"LinearRegression\",\n",
      "\"LearningType\": \"Regression\",\n",
      "\"requirements\":[\"NON-MISSING-VALUES\",\"NUMERICAL\"]\n",
      "}\n",
      "\n",
      "float_100_350.csv: 0.04850316047668457\n",
      "float_100_50.csv: 0.009998798370361328\n",
      "float_300_350.csv: 0.06453680992126465\n",
      "float_300_50.csv: 0.010003805160522461\n",
      "float_600_350.csv: 0.09606361389160156\n",
      "float_600_50.csv: 0.014004230499267578\n",
      "{\n",
      "\"class\": \"sklearn.preprocessing.LabelEncoder\",\n",
      "\"name\": \"LabelEncoder\",\n",
      "\"isArray\": \"true\",\n",
      "\"requirements\":[\"NON-MISSING-VALUES\"]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import importlib\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import time\n",
    "\n",
    "class Primitive(object):\n",
    "\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "def class_for_name(module_name, class_name):\n",
    "    try:\n",
    "        # load the module, will raise ImportError if module cannot be loaded\n",
    "        m = importlib.import_module(module_name)\n",
    "        # get the class, will raise AttributeError if class cannot be found\n",
    "        c = getattr(m, class_name)()\n",
    "        return c\n",
    "    except:\n",
    "        print('Could not load module: '+module_name+'.'+class_name)\n",
    "        return -1\n",
    "\n",
    "#Data: dataset to test (from the test datasets that illustrate different requirements)\n",
    "#Primitive: primitive being tested. We assume it has the fit() method\n",
    "#The second field returned indicates whether the primitives needs an array or not\n",
    "def passTest(data, primitive):\n",
    "    target = data.iloc[:,-1]\n",
    "    train = data.drop(data.columns[[len(data.columns)-1]], axis=1) #drop target column (the last one)\n",
    "    #test\n",
    "    try:\n",
    "        y_pred = primitive.fit(train,target).predict(train)# Not all primitives have a predict, but should have fit\n",
    "        #print(\"PASSED: \"+data.name)\n",
    "        #print (y_pred)\n",
    "        return True, False\n",
    "    except Exception as e:\n",
    "        #print(e)\n",
    "        try:\n",
    "            y_pred = primitive.fit(train).transform(train)\n",
    "            #print (y_pred)\n",
    "            return True, False\n",
    "        except:\n",
    "            #Some primitives can only be applied to arrays, not matrix!\n",
    "            try:\n",
    "                for col in train.columns:\n",
    "                    #print (col)\n",
    "                    #Need to do the transform, otherwise exceptions may not be raised\n",
    "                    y_pred = primitive.fit(train[col]).transform(train[col])\n",
    "                return True, True\n",
    "            except: \n",
    "                return False, False\n",
    "        #print(\"NOT PASSED: \" +data.name)\n",
    "        \n",
    "\n",
    "\n",
    "#Path: String with the path to the dataset folders. The system assumes to have three: clean_data, requirement_data and performance_data\n",
    "#Primitive module name: string with the module name. E.g., 'sklearn.svm'\n",
    "#Primitive name: string with the name of the primitive to be loaded. E.g., 'SVC'\n",
    "#testPerformance: boolean that is true if you want to test the performance tests (will require more time)\n",
    "def getPrimitiveRequirements(path, primitiveModuleName, primitiveName, testPerformance):\n",
    "    CLEAN = path + \"clean_data\"\n",
    "    REQ = path + \"requirement_data\"\n",
    "    PERF = path + \"performance_data\"\n",
    "    primExec =  class_for_name(primitiveModuleName,primitiveName)\n",
    "    if(primExec == -1):\n",
    "        print(\"The primitive module could not be loaded.\")\n",
    "        return -1\n",
    "    prim = Primitive(primitiveName)\n",
    "    prim.id = primitiveModuleName+\".\"+primitiveName\n",
    "    #Clean data files: all primitives should pass these tests\n",
    "    data_clean_int = pd.read_csv(CLEAN +'/int_clean_data.csv')\n",
    "    data_clean_float = pd.read_csv(CLEAN +'/float_clean_data.csv')\n",
    "    data_clean_int.name = \"CLEAN DATA INT\" \n",
    "    data_clean_float.name = \"CLEAN DATA FLOAT\"\n",
    "    \n",
    "    if not hasattr(primExec, 'fit'):\n",
    "        print(\"Primitive does not have fit method. No requirements considered\")\n",
    "        return -1\n",
    "    \n",
    "    passed, p = (passTest(data_clean_int, primExec)) and (passTest(data_clean_float, primExec))\n",
    "    #print(passed)\n",
    "    if(not passed):\n",
    "        print(\"The primitive \"+primitiveName+\" cannot execute the clean datasets. No further requirements addressed\")\n",
    "        return -1\n",
    "    \n",
    "    if hasattr(primExec, 'predict'):\n",
    "        #primitive is a classifier/regression\n",
    "        target = data_clean_float.iloc[:,-1]\n",
    "        train = data_clean_float.drop(data_clean_float.columns[[len(data_clean_float.columns)-1]], axis=1) #drop target column (the last one)\n",
    "        y_pred = primExec.fit(train,target).predict(train)\n",
    "        \n",
    "        if issubclass(y_pred.dtype.type, np.floating):\n",
    "            prim.isRegression = True\n",
    "        else:\n",
    "            prim.isClassification = True\n",
    "    \n",
    "    #Rest of the tests\n",
    "    onlyfiles = [f for f in listdir(REQ) if isfile(join(REQ, f))]\n",
    "    for d in onlyfiles:\n",
    "        data = pd.read_csv(REQ+\"/\"+d)\n",
    "        data.name = d\n",
    "        passed,array = passTest(data, primExec)\n",
    "        if (\"missing\" in data.name) and (not passed):\n",
    "            #print(\"Primitive cannot handle missing values\")\n",
    "            prim.missing = False\n",
    "        if (\"categorical\" in data.name) and (not passed):\n",
    "            #print(\"Primitive cannot handle string/categorical values\")\n",
    "            prim.categorical = False\n",
    "        if (\"unique\" in data.name) and (not passed):\n",
    "            #print(\"Primitive cannot handle having a column of unique values\")\n",
    "            prim.unique = False\n",
    "        if (\"negative\" in data.name) and (not passed):\n",
    "            #print(\"Primitive cannot handle negative values\")\n",
    "            prim.negative = False\n",
    "        if(array):\n",
    "            prim.isArray = True\n",
    "    if(testPerformance):\n",
    "        onlyfiles = [f for f in listdir(PERF) if isfile(join(PERF, f))]\n",
    "        for d in onlyfiles:\n",
    "            data = pd.read_csv(PERF+\"/\"+d)\n",
    "            data.name = d\n",
    "            start = time.time()\n",
    "            passed,array = passTest(data, primExec)\n",
    "            end = time.time()\n",
    "            print(data.name +\": \"+ str(end - start))      \n",
    "    return prim\n",
    "\n",
    "\n",
    "#assumes certain variables of the JSON have been initialized.\n",
    "#NON-MISSING-VALUES: The primitive cannot handle missing values\n",
    "#NUMERICAL: The primitive cannot handle string/categorical values\n",
    "#NOT-UNIQUE: The primitive cannot handle columns with a single value\n",
    "#NON-NEGATIVE: The primitive needs to have positive values\n",
    "#ARRAY: The primitive needs to be an array, not a matrix\n",
    "\n",
    "#Will produce a JSON file that looks like:\n",
    "#{\n",
    "#        \"class\": \"sklearn.linear_model.LogisticRegression\",\n",
    "#        \"name\": \"LogisticRegression\", \n",
    "#        \"requirements\": [\"NUMERICAL\"]\n",
    "#    }\n",
    "def primitiveToJSON(primitive):\n",
    "    try:\n",
    "        json = \"{\\n\" + \"\\\"class\\\": \\\"\"+primitive.id+\"\\\",\\n\"\n",
    "        json = json + \"\\\"name\\\": \\\"\"+primitive.name+\"\\\",\\n\"\n",
    "        if hasattr(primitive, 'isArray'):\n",
    "            json = json + \"\\\"isArray\\\": \\\"true\\\",\\n\"\n",
    "        if hasattr(primitive, 'isClassification'):\n",
    "            json = json + \"\\\"LearningType\\\": \\\"Classification\\\",\\n\"\n",
    "        if hasattr(primitive, 'isRegression'):\n",
    "            json = json + \"\\\"LearningType\\\": \\\"Regression\\\",\\n\"\n",
    "        #If it's classification on regression, then add the task:\"Modeling\"\n",
    "        json = json + \"\\\"requirements\\\":[\"\n",
    "        if hasattr(primitive, 'missing') or hasattr(primitive, 'categorical') or hasattr(primitive, 'unique') or hasattr(primitive, 'negative'):\n",
    "            #attributes are only there if false\n",
    "            if hasattr(primitive, 'missing'):\n",
    "                json = json + \"\\\"NON-MISSING-VALUES\\\",\"\n",
    "            if hasattr(primitive, 'categorical'):\n",
    "                json = json + \"\\\"NUMERICAL\\\",\"\n",
    "            if hasattr(primitive, 'unique'):\n",
    "                json = json + \"\\\"NOT-UNIQUE\\\",\"\n",
    "            if hasattr(primitive, 'negative'):\n",
    "                json = json + \"\\\"NON-NEGATIVE\\\",\"\n",
    "            json = json[:-1]\n",
    "        json = json + \"]\\n}\\n\"\n",
    "        return json\n",
    "    except:\n",
    "        print(\"Cannot serialize primitive\")\n",
    "      \n",
    "def allPrimitivesToText(jsonFile):\n",
    "    output = \"\"\n",
    "    for i in data['search_primitives']:\n",
    "        if i[\"is_class\"]: #necessary because otherwise it will attempt to try many primitives that may even download data\n",
    "            primitive = i[\"id\"]\n",
    "            print (primitive [:primitive.rindex('.')]+\".\"+primitive [primitive.rindex('.')+1:])\n",
    "            p = getPrimitiveRequirements(DATADIR,primitive [:primitive.rindex('.')],primitive [primitive.rindex('.')+1:],False)\n",
    "            if(p != -1):\n",
    "                output += primitiveToJSON(p)\n",
    "                #print (primitiveToJSON(p))\n",
    "    return output\n",
    "        \n",
    "#Main script        \n",
    "DATADIR = \"data_profiler/\" #Dir with the profiling datasets\n",
    "print (primitiveToJSON(getPrimitiveRequirements(DATADIR,'sklearn.svm','SVC',True)))\n",
    "print (primitiveToJSON(getPrimitiveRequirements(DATADIR,'sklearn.linear_model','LinearRegression',True)))\n",
    "print (primitiveToJSON(getPrimitiveRequirements(DATADIR,'sklearn.preprocessing','LabelEncoder',True)))\n",
    "\n",
    "#print (primitiveToJSON(getPrimitiveRequirements(DATADIR,'sklearn.feature_extraction.text','TfidfVectorizer',False)))\n",
    "#sklearn.metrics.scorer.get_scorer\n",
    "#print (primitiveToJSON(getPrimitiveRequirements(DATADIR,'sklearn.linear_model.sgd_fast','Regression',False)))\n",
    "#print (primitiveToJSON(getPrimitiveRequirements(DATADIR,'sklearn.decomposition.dict_learning','DictionaryLearning',False)))\n",
    "\n",
    "\n",
    "\n",
    "#from pprint import pprint\n",
    "#import json\n",
    "\n",
    "#with open('sklearn.json') as data_file:    \n",
    "#    data = json.load(data_file)\n",
    "#print(allPrimitivesToText(data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
