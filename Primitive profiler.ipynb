{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\"class\": \"sklearn.svm.SVC\",\n",
      "\"name\": \"SVC\",\n",
      "\"requirements\":[\"NON-MISSING-VALUES\",\"NUMERICAL\"]\n",
      "}\n",
      "\n",
      "{\n",
      "\"class\": \"sklearn.linear_model.LogisticRegression\",\n",
      "\"name\": \"LogisticRegression\",\n",
      "\"requirements\":[\"NON-MISSING-VALUES\",\"NUMERICAL\"]\n",
      "}\n",
      "\n",
      "{\n",
      "\"class\": \"sklearn.preprocessing.LabelEncoder\",\n",
      "\"name\": \"LabelEncoder\",\n",
      "\"requirements\":[\"NON-MISSING-VALUES\",\"ARRAY\"]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import importlib\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "\n",
    "def class_for_name(module_name, class_name):\n",
    "    try:\n",
    "        # load the module, will raise ImportError if module cannot be loaded\n",
    "        m = importlib.import_module(module_name)\n",
    "        # get the class, will raise AttributeError if class cannot be found\n",
    "        c = getattr(m, class_name)()\n",
    "        return c\n",
    "    except:\n",
    "        print('Could not load module: '+module_name+'.'+class_name)\n",
    "        return -1\n",
    "\n",
    "#Data: dataset to test (from the test datasets that illustrate different requirements)\n",
    "#Primitive: primitive being tested. We assume it has the fit() method\n",
    "#The second field returned indicates whether the primitives needs an array or not\n",
    "def passTest(data, primitive):\n",
    "    target = data.iloc[:,-1]\n",
    "    train = data.drop(data.columns[[len(data.columns)-1]], axis=1) #drop target column (the last one)\n",
    "    #test\n",
    "    try:\n",
    "        y_pred = primitive.fit(train,target)#.predict(train)# Not all primitives have a predict, but should have fit\n",
    "        #print(\"PASSED: \"+data.name) \n",
    "        return True, False\n",
    "    except:\n",
    "        #some primitives do NOT have the train for the fit method\n",
    "        try:\n",
    "            y_pred = primitive.fit(train)\n",
    "            return True, False\n",
    "        except:\n",
    "            #Some primitives can only be applied to arrays, not matrix!\n",
    "            try:\n",
    "                for col in train.columns:\n",
    "                    #print (col)\n",
    "                    #Need to do the transform, otherwise exceptions may not be raised\n",
    "                    y_pred = primitive.fit(train[col]).transform(train[col])\n",
    "                return True, True\n",
    "            except: \n",
    "                return False, False\n",
    "        #print(\"NOT PASSED: \" +data.name)\n",
    "        \n",
    "##########TO DO: A FUNCTION THAT DETERMINES WHETHER THE PRIMITIVE NEEDS \n",
    "   \n",
    "\n",
    "#Path: String with the path to the dataset folders. The system assumes to have three: clean_data, requirement_data and performance_data\n",
    "#Primitive module name: string with the module name. E.g., 'sklearn.svm'\n",
    "#Primitive name: string with the name of the primitive to be loaded. E.g., 'SVC'\n",
    "#testPerformance: boolean that is true if you want to test the performance tests (will require more time)\n",
    "def getPrimitiveRequirements(path, primitiveModuleName, primitiveName, testPerformance):\n",
    "    CLEAN = path + \"clean_data\"\n",
    "    REQ = path + \"requirement_data\"\n",
    "    PERF = path + \"performance_data\"\n",
    "    prim =  class_for_name(primitiveModuleName,primitiveName)\n",
    "    prim.id = primitiveModuleName+\".\"+primitiveName\n",
    "    prim.name = primitiveName\n",
    "    if(prim == -1):\n",
    "        print(\"The primitive module could not be loaded.\")\n",
    "        return prim\n",
    "    #Clean data files: all primitives should pass these tests\n",
    "    data_clean_int = pd.read_csv(CLEAN +'/int_clean_data.csv')\n",
    "    data_clean_float = pd.read_csv(CLEAN +'/float_clean_data.csv')\n",
    "    data_clean_int.name = \"CLEAN DATA INT\" \n",
    "    data_clean_float.name = \"CLEAN DATA FLOAT\"\n",
    "    passed = (passTest(data_clean_int, prim)) and (passTest(data_clean_float, prim))\n",
    "    if(not passed):\n",
    "        print(\"The primitive \"+primitiveName+\" cannot execute the clean datasets. No further requirements addressed\")\n",
    "        return\n",
    "    #Rest of the tests\n",
    "    onlyfiles = [f for f in listdir(REQ) if isfile(join(REQ, f))]\n",
    "    for d in onlyfiles:\n",
    "        data = pd.read_csv(REQ+\"/\"+d)\n",
    "        data.name = d\n",
    "        passed,array = passTest(data, prim)\n",
    "        if (\"missing\" in data.name) and (not passed):\n",
    "            #print(\"Primitive cannot handle missing values\")\n",
    "            prim.missing = False\n",
    "        if (\"categorical\" in data.name) and (not passed):\n",
    "            #print(\"Primitive cannot handle string/categorical values\")\n",
    "            prim.categorical = False\n",
    "        if (\"unique\" in data.name) and (not passed):\n",
    "            #print(\"Primitive cannot handle having a column of unique values\")\n",
    "            prim.unique = False\n",
    "        if (\"negative\" in data.name) and (not passed):\n",
    "            #print(\"Primitive cannot handle negative values\")\n",
    "            prim.negative = False\n",
    "        if(array):\n",
    "            prim.isArray = True\n",
    "    if(testPerformance):\n",
    "        #TO DO\n",
    "        print(\"TO DO: run the performance tests\")\n",
    "            \n",
    "    return prim\n",
    "\n",
    "#assumes certain variables of the JSON have been initialized.\n",
    "#NON-MISSING-VALUES: The primitive cannot handle missing values\n",
    "#NUMERICAL: The primitive cannot handle string/categorical values\n",
    "#NOT-UNIQUE: The primitive cannot handle columns with a single value\n",
    "#NON-NEGATIVE: The primitive needs to have positive values\n",
    "#ARRAY: The primitive needs to be an array, not a matrix\n",
    "\n",
    "#Will produce a JSON file that looks like:\n",
    "#{\n",
    "#        \"class\": \"sklearn.linear_model.LogisticRegression\",\n",
    "#        \"name\": \"LogisticRegression\", \n",
    "#        \"requirements\": [\"NUMERICAL\"]\n",
    "#    }\n",
    "def primitiveToJSON(primitive):\n",
    "    try:\n",
    "        json = \"{\\n\" + \"\\\"class\\\": \\\"\"+primitive.id+\"\\\",\\n\"\n",
    "        json = json + \"\\\"name\\\": \\\"\"+primitive.name+\"\\\",\\n\"\n",
    "        json = json + \"\\\"requirements\\\":[\"\n",
    "        #attributes are only there if false\n",
    "        if hasattr(primitive, 'missing'):\n",
    "            json = json + \"\\\"NON-MISSING-VALUES\\\",\"\n",
    "        if hasattr(primitive, 'categorical'):\n",
    "            json = json + \"\\\"NUMERICAL\\\",\"\n",
    "        if hasattr(primitive, 'unique'):\n",
    "            json = json + \"\\\"NOT-UNIQUE\\\",\"\n",
    "        if hasattr(primitive, 'negative'):\n",
    "            json = json + \"\\\"NON-NEGATIVE\\\",\"\n",
    "        if hasattr(primitive, 'isArray'):\n",
    "            json = json + \"\\\"ARRAY\\\",\"\n",
    "        json = json[:-1]\n",
    "        json = json + \"]\\n}\\n\"\n",
    "        return json\n",
    "    except:\n",
    "        print(\"Cannot serialize primitive\")\n",
    "        \n",
    "        \n",
    "#Main script        \n",
    "DATADIR = \"data_profiler/\" #Dir with the profiling datasets\n",
    "print (primitiveToJSON(getPrimitiveRequirements(DATADIR,'sklearn.svm','SVC',False)))\n",
    "print (primitiveToJSON(getPrimitiveRequirements(DATADIR,'sklearn.linear_model','LogisticRegression',False)))\n",
    "print (primitiveToJSON(getPrimitiveRequirements(DATADIR,'sklearn.preprocessing','LabelEncoder',False)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Test code below\n",
    "#Files with different issues: missing values, constant values, etc.\n",
    "#from os import listdir\n",
    "#from os.path import isfile, join\n",
    "#onlyfiles = [f for f in listdir(REQ) if isfile(join(REQ, f))]\n",
    "#print(onlyfiles)\n",
    "#for d in onlyfiles:\n",
    "#    data = pd.read_csv(DATADIR+\"/requirement_data\"+\"/\"+d)\n",
    "#    data.name = d\n",
    "#    passTest(data, prim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
